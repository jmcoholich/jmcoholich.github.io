<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload="this.media='all'"><meta name=author content="Jeremiah Coholich"><meta name=description content="Under Review"><link rel=alternate hreflang=en-us href=https://jmcoholich.github.io/publication/hrl_optim/><meta name=theme-color content="#1565c0"><script src=/js/mathjax-config.js></script>
<link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload="this.media='all'"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload="this.media='all'"><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload="this.media='all'"><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload="this.media='all'" disabled><script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js integrity crossorigin=anonymous async></script>
<link rel=stylesheet href=/css/wowchemy.95d53890c5839471cef2375b6c449b9f.css><script async src="https://www.googletagmanager.com/gtag/js?id=G-QYSG8SXEWT"></script>
<script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag('event','click',{event_category:'outbound',event_label:e,transport_type:'beacon',event_callback:function(){t!=='_blank'&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=='A'||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute('target'))}gtag('js',new Date),gtag('config','G-QYSG8SXEWT',{}),gtag('set',{cookie_flags:'SameSite=None;Secure'}),document.addEventListener('click',onClickCallback,!1)</script><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_huc310f1ac1642ff51805cd109dc789c7d_32737_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_huc310f1ac1642ff51805cd109dc789c7d_32737_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://jmcoholich.github.io/publication/hrl_optim/><meta property="twitter:card" content="summary_large_image"><meta property="og:site_name" content="Jeremiah Coholich"><meta property="og:url" content="https://jmcoholich.github.io/publication/hrl_optim/"><meta property="og:title" content="Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion | Jeremiah Coholich"><meta property="og:description" content="Under Review"><meta property="og:image" content="https://jmcoholich.github.io/publication/hrl_optim/featured.png"><meta property="twitter:image" content="https://jmcoholich.github.io/publication/hrl_optim/featured.png"><meta property="og:locale" content="en-us"><script type=application/ld+json>{"@context":"https://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://jmcoholich.github.io/publication/hrl_optim/"},"headline":"Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion","image":["https://jmcoholich.github.io/publication/hrl_optim/featured.png"],"datePublished":"0001-01-01T00:00:00Z","dateModified":"0001-01-01T00:00:00Z","author":{"@type":"Person","name":"Jeremiah M Coholich"},"publisher":{"@type":"Organization","name":"Jeremiah Coholich","logo":{"@type":"ImageObject","url":"https://jmcoholich.github.io/media/icon_huc310f1ac1642ff51805cd109dc789c7d_32737_192x192_fill_lanczos_center_3.png"}},"description":"Under Review"}</script><title>Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion | Jeremiah Coholich</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=e68331a122bca9f752a1ec47c4070d50><script src=/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Jeremiah Coholich</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Jeremiah Coholich</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#awards><span>Awards</span></a></li><li class=nav-item><a class=nav-link href=/#posts><span>Blog</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><div class=pub><div class="article-container pt-3"><h1>Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion</h1><div class=article-metadata><div><span>Jeremiah M Coholich</span>, <span>Muhammad Ali Murtaza</span>, <span>Seth Hutchinson</span>, <span>Zsolt Kira</span></div><span class=article-date>January, 0001</span></div><div class="btn-links mb-3"><a class="btn btn-outline-primary btn-page-header" href=/publication/hrl_optim/hrl_optim.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header" href=https://github.com/jmcoholich/isaacgym target=_blank rel=noopener>Code</a></div></div><div class="article-header article-container featured-image-wrapper mt-4 mb-4" style=max-width:624px;max-height:431px><div style=position:relative><img src=/publication/hrl_optim/featured_hu75b80d95036edc6148ca3d753a0adcb0_72093_720x2500_fit_q75_h2_lanczos_3.webp width=624 height=431 alt class=featured-image>
<span class=article-header-caption>The proposed planning and control architecture</span></div></div><div class=article-container><h3>Abstract</h3><p class=pub-abstract>We propose a novel hierarchical reinforcement learning framework for quadruped locomotion over challenging terrains. Our approach incorporates a two-layer hierarchy where a high-level planner (HLP) selects optimal goals for a low-level policy (LLP). The LLP is trained using an on-policy actor-critic RL algorithm and is given footstep placements as goals. The HLP does not require any additional training or environment samples, since it operates via an online optimization process over the value function of the LLP. We demonstrate the benefits of this framework by comparing it against an end-to-end reinforcement learning (RL) approach, highlighting improvements in its ability to achieve higher rewards with fewer collisions across an array of different terrains.</p><div class=row><div class=col-md-1></div><div class=col-md-10><div class=row><div class="col-12 col-md-3 pub-row-heading">Type</div><div class="col-12 col-md-9"><a href=/publication/#1>Conference paper</a></div></div></div><div class=col-md-1></div></div><div class="d-md-none space-below"></div><div class=space-below></div><div class=article-style></div><div class=article-tags><a class="badge badge-light" href=/tag/published/>published</a></div><div class=share-box><ul class=share><li><a href="https://twitter.com/intent/tweet?url=https://jmcoholich.github.io/publication/hrl_optim/&text=Hierarchical%20Reinforcement%20Learning%20and%20Value%20Optimization%20for%20Challenging%20Quadruped%20Locomotion" target=_blank rel=noopener class=share-btn-twitter aria-label=twitter><i class="fab fa-twitter"></i></a></li><li><a href="mailto:?subject=Hierarchical%20Reinforcement%20Learning%20and%20Value%20Optimization%20for%20Challenging%20Quadruped%20Locomotion&body=https://jmcoholich.github.io/publication/hrl_optim/" target=_blank rel=noopener class=share-btn-email aria-label=envelope><i class="fas fa-envelope"></i></a></li><li><a href="https://www.linkedin.com/shareArticle?url=https://jmcoholich.github.io/publication/hrl_optim/&title=Hierarchical%20Reinforcement%20Learning%20and%20Value%20Optimization%20for%20Challenging%20Quadruped%20Locomotion" target=_blank rel=noopener class=share-btn-linkedin aria-label=linkedin-in><i class="fab fa-linkedin-in"></i></a></li><li><a href="https://reddit.com/submit?url=https://jmcoholich.github.io/publication/hrl_optim/&title=Hierarchical%20Reinforcement%20Learning%20and%20Value%20Optimization%20for%20Challenging%20Quadruped%20Locomotion" target=_blank rel=noopener class=share-btn-reddit aria-label=reddit-alien><i class="fab fa-reddit-alien"></i></a></li></ul></div></div></div></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2024 Jeremiah Coholich</p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.e66e385e2f1df861699d60acd7a9c670.js></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.c251366b4128fd5e6b046d4c97a62a51.js type=module></script>
<script src=/en/js/wowchemy.min.ab2f2890dbe3e2e83579366d3d6e8fd9.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>