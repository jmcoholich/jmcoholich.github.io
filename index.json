[{"authors":null,"categories":null,"content":" I am a Robotics PhD student at Georgia Tech in the Robotics Perception and Learning (RIPL) Lab. My research involves imitation learning and reinforcement learning for robots. During the Fall of 2025, I was an AI resident at 1X Technologies, working on scaling simulation. I plan to graduate with my PhD in the Summer of 2026. My dissertation will be on robot data augmentation.\nIn the summer of 2023 I was an intern at Honda Research Institute working on deep learning-based dexterous manipulation under Jinda Cui and Soshi Iba. During my bachelor’s degree, I was an undergraduate research assistant in the Human Centered Robotics Lab where I was mentored by Dr. Luis Sentis and Dr. Gray Thomas. I spent my summers interning at SpaceX, Harmonic Bionics, and NASA JPL. Additionally, I spent a large amount of time co-founding and leading Longhorn Racing Electric. During my PhD, I’ve the pleasure of mentoring two masters students, Justin Wit and Robert Azarcon.\nCheck out the new VR teleoperated setup I put together:\n","date":1751155200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1751155200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a Robotics PhD student at Georgia Tech in the Robotics Perception and Learning (RIPL) Lab. My research involves imitation learning and reinforcement learning for robots. During the Fall of 2025, I was an AI resident at 1X Technologies, working on scaling simulation.","tags":null,"title":"Jeremiah Coholich","type":"authors"},{"authors":["Jeremiah Coholich"],"categories":null,"content":"This blog post is about my experience using FoundationPose with LangSAM. It is meant to provide advice for others and qualitative third-party results for reference.\nTL;DR FoundationPose combined with LangSAM works somewhat well out of the box, but struggles significantly with small objects and occlusions. I was able to improve results on some tasks by adding an L1 temporal-consistency score on bounding boxes and a few manual data annotations. The model/code has no built-in way of dealing with objects going out-of-frame or complete occlusion, which is a big practical limitation. We’re still exploring newer models and other ways to improve results. Also, see the Conclusion.\nJump to Results on Stack-Blocks\nJump to Results on Stack-Plates\nJump to Results on Stack-Cups\nFoundationPose Overview FoundationPose is a 6D object pose estimation model. It is trained on synthetically-augmented Objaverse objects. At inference time, the model generates multiple pose hypotheses, ranks them, and outputs the rank 0 pose estimate. Unlike previous works, FoundationPose does not need to build a NeRF of the object first.\nFoundationPose operates either in a model-based or model-free mode, where “model” refers to a 3D mesh of the tracked object. To run FoundationPose model-free, several reference images of the object need to be supplied. I’ve only tried the model-based version of FoundationPose.\nFor more details, see the paper, however an in-depth understanding of FoundationPose is not required to use the model. Below is an overview of their method (Figure 2 from the paper).\nFoundationPose method overview (Source: https://nvlabs.github.io/FoundationPose/) LangSAM Overview LangSAM is not a new method or architecture, but actually just code which combines the Segment Anything (SAM) model from Meta with the Grounding DINO open-world object detector. Here, an understanding of what is really going on is helpful for effectively using and modifying LangSAM.\nSAM is a powerful segmentation model that can generate pixel-wise segmentations for anything in an image, as the name implies. SAM takes an image and a prompt and outputs a segmentation mask. The prompt can either be points, a bounding box, or a text string. However, Meta has not released a version of SAM with text conditioning. Fortunately, this capability can be reproduced by adding Grounding DINO.\nAn overview of the Segment Anything model (Source: https://arxiv.org/abs/2304.02643) Example images segmented by SAM containing 400 to 500 masks per image (Source: https://arxiv.org/abs/2304.02643) Grounding DINO is an open-world object detector that takes a string of text and outputs bounding box proposals. It was created by fusing a closed-set object detector, DINO, with a text encoder, BERT. LangSAM takes the bounding box proposals from Grounding DINO and feeds them into SAM to obtain a pixel-wise segmentation mask. This blog post explains LangSAM in much more detail.\nWe have two reasons for using LangSAM:\nFoundationPose requires a segmentation mask of the tracked object(s) in the first frame to initialize pose estimation. We wanted a database of object segmentations for a data-augmentation task (not covered in this post). Off-the-Shelf Performance FoundationPose requires RGBD video frames, a CAD model, camera intrinsics, and a binary segmentation mask of the tracked object in the first frame.\nBelow is a visualization of our input video of a VR-teleoperated demonstration of a block-stacking task.\nThe three views are captured with RealSense D435 cameras running at 1280x720 resolution. The intrinsics matrix is:\n$$ K = \\begin{bmatrix} 912.0 \u0026amp; 0.0 \u0026amp; 640.0 \\\\ 0.0 \u0026amp; 912.0 \u0026amp; 360.0 \\\\ 0.0 \u0026amp; 0.0 \u0026amp; 1.0 \\end{bmatrix} $$\nThe cups, blocks, and plates we used for experiments were purchased on Amazon:\nCups: https://a.co/d/9PSu2UX Blocks (painted after purchasing): https://a.co/d/i5k3pBq Plates: https://a.co/d/6hOiS2a (These are not affiliate links)\nThe CAD models I created for each of them are available here.\nFoundationPose first requires an initial guess for object translation and rotation at every frame. The initial guess is then refined for a set number of iterations (default: 5) to produce the final estimate. For every frame except the first one, the pose estimate of the previous frame is used for initialization. When processing the first frame, FoundationPose generates 240 initial rotation guesses through sampling points and rotations on an icosphere. The first-frame initial guess for translation is obtained through the user-provided segmentation mask.\nI modified the FoundationPose code to track all three cubes at once with a simple “for” loop. Below are the first results. I’m only running tracking on the front camera view.\nClearly, there are some issues; the model is unable to track the blocks once they are moved.\nFoundationPose with L1 Bounding-Box Consistency My first idea for improving these results was to condition the pose estimates for every frame on the segmentation masks from LangSAM (vs …","date":1751155200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1751155200,"objectID":"f2fa789e1a78128078b875dd1da0eb29","permalink":"https://jmcoholich.github.io/post/foundationpose/","publishdate":"2025-06-29T00:00:00Z","relpermalink":"/post/foundationpose/","section":"post","summary":"I used three foundation models -- SAM, Grounded DINO, and FoundationPose -- to obtain 6D pose estimates on raw RGBD robot demonstrations. In order to improve results, I added L1-consistent bounding boxes and various annotations to the data. Ultimately, the results were mixed, and we're still looking for improvements.","tags":null,"title":"FoundationPose and LangSAM for Robotics","type":"post"},{"authors":["Jeremiah Coholich","Justin Wit","Robert Azarcon","Zsolt Kira"],"categories":null,"content":" ","date":1746144e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1746144e3,"objectID":"be475be76b1efc0821d79546d3450290","permalink":"https://jmcoholich.github.io/publication/iros_2025/","publishdate":"2025-05-02T00:00:00Z","relpermalink":"/publication/iros_2025/","section":"publication","summary":"Submitted to 2026 International Conference on Robotics and Automation (ICRA)","tags":["published"],"title":"Sim2real Image Translation Enables ViewpointRobust Policies from Fixed-Camera Datasets","type":"publication"},{"authors":["Jeremiah Coholich","Muhammad Ali Murtaza","Seth Hutchinson","Zsolt Kira"],"categories":null,"content":" ","date":1745539200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1745539200,"objectID":"e68331a122bca9f752a1ec47c4070d50","permalink":"https://jmcoholich.github.io/publication/hrl_optim/","publishdate":"2025-04-25T00:00:00Z","relpermalink":"/publication/hrl_optim/","section":"publication","summary":"2025 American Control Conference (ACC)","tags":["published"],"title":"Hierarchical Reinforcement Learning and Value Optimization for Challenging Quadruped Locomotion","type":"publication"},{"authors":["Jeremiah Coholich","Harsh Maheshwari","Simar Kareer","Arun Ramachandran"],"categories":null,"content":" ","date":1671062400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1671062400,"objectID":"6d846117d652ecdd3a20fd1581254181","permalink":"https://jmcoholich.github.io/publication/cs_8803_mean_teacher/","publishdate":"2022-12-15T00:00:00Z","relpermalink":"/publication/cs_8803_mean_teacher/","section":"publication","summary":"We propose and evaluate two variants to the mean teacher self-distillation technique (CS 8803 Learning with Limited Supervision final project)","tags":["unpublished"],"title":"Improving the Student-Teacher Approach for Semi-Supervised Semantic Segmentation","type":"publication"},{"authors":["Jeremiah Coholich"],"categories":null,"content":" When I first started studying reinforcement learning (RL), I implemented Proximal Policy Optimization (PPO) from scratch using only the psuedocode on OpenAI’s website. It didn’t work and failed to obtain nearly any reward on most OpenAI Gym environments. It took a few more months of debugging, reading other RL implementations, and talking to colleagues to get things working. My conversations with other Georgia Tech students revealed that initially struggling to do basic things with RL was not uncommon. These blog posts do a great job of explaining the difficulty with RL and really resonate with my own experiences.\nIn hindsight, there was no single major flaw with my initial PPO implementation, but rather many small tricks and optimizations that were missing. The purpose of this post is to enumerate these tricks and provide references to code where they are implemented. They are roughly ordered in descending order of importance. Knowledge of some of these tricks is only necessary if you are implementing an RL algorithm from scratch, as most public implementations will already include them. However, knowing of their existence will enable you to debug more effectively and make changes more intelligently.\nDifferent RL implementations will include a slightly different set of tricks. As evidence of their importance, check out this figure (below) from the paper Deep Reinforcement Learning that Matters. The authors show empirically that different popular implementions of the same RL algorithm differ significantly in performance on standard RL benchmarks, even when controlling for hyperparameters and network architecture.\nFigure 6 from Deep Reinforcement Learning that Matters, plotting the performance of different RL implementations averaged over 5 random seeds. These variations can be explained by differences in implementation and different PyTorch/TF versions.\nNow for some disclaimers – nearly all of my experience comes from training on-policy algorithms for continuous control, so there may be useful tips for discrete/off-policy settings that I’m missing. Also, RL is a super-hot field and perhaps some of the content in this post is already outdated. Hopefully, this blog is at least useful to someone starting out like I was. Please don’t hesitate to reach out to me if you think there is something important missing!\nMost of the examples will come from either of these two RL implementations:\npytorch-a2c-ppo-acktr-gail RL Games Implementing an RL algorithm from scratch is an excellent way to learn. However, if you just need to get something working quickly, you should instead just fork a popular repo and start from there. Here are some suggestions:\nStable Baselines3 RL Games pytorch-a2c-ppo-acktr RLlib Contents:\nObservation and Normalization Clipping Dense Rewards Hyperparameter Tuning Gradient Normalization and Clipping Reward Normalization and Clipping Advantage Standardization Bootstrapping Incomplete Episodes Generalized Advantage Estimation Entropy Decay Value Network Loss Clipping Learning Rate Scheduling Thanks to Andrew Szot and Mathew Piotrowicz for reading drafts of this and providing feedback.\nObservation Normalization and Clipping In RL, the inputs to the policy and value networks are observations, which can consist of values that differ by orders of magnitude. For example, if you are learning a policy to control a robot, your observation could contain joint angles ranging from $ -\\frac{\\pi}{2} $ to $ \\frac{\\pi}{2} $ radians and a robot position coordinate that lies between 0 and 1000 meters. Normalizing the input space to eliminate this difference in scale leads to more stable training and faster convergence. This should be nothing new to those with prior experience training neural networks.\nThe two most common methods for preprocessing are standardization and rescaling. Standardization refers to subtracting the mean and dividing by the standard deviation of the data so that each dimension approximates a standard normal distribution. Rescaling means mapping the data to the range $ \\left[0, 1\\right] $ by subtacting the min and dividing by the range. In either case, clipping should also be applied after normalization. Neural networks are bad at extrapolation, and outliers can produce unexpected outputs. In my work, observations are clipped to $[-5.0, 5.0]$ after standardization.\nIn supervised learning, statistics calculated over the training set are used to normalize each sample. In RL, this isn’t possible because the dataset (consisting of interactions with the environment) is collected online and the statistics change continuously. Because of this, you need to calculate an online mean and standard deviation. Most RL codebases use an implementation of Welford’s Online Algorithm like this one from Stable Baselines3.\nThis online approach is best when your algorithm needs to work on many different environments. However, it often causes an initial drop in performance (red circle below) as the mean and …","date":1663372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663372800,"objectID":"a720526db105fcb3d60fe9fbb213b85a","permalink":"https://jmcoholich.github.io/post/rl_bag_of_tricks/","publishdate":"2022-09-17T00:00:00Z","relpermalink":"/post/rl_bag_of_tricks/","section":"post","summary":"When I first started studying reinforcement learning (RL), I implemented Proximal Policy Optimization (PPO) from scratch using only the psuedocode on OpenAI’s website. It didn’t work and failed to obtain nearly any reward on most OpenAI Gym environments.","tags":null,"title":"A Bag of Tricks for Deep Reinforcement Learning","type":"post"},{"authors":["Jeremiah Coholich"],"categories":null,"content":" The Google Foobar challenge is a programming challenge used by Google for recruiting. You must be invited to participate (article with more info). The challenge contains five levels of increasing difficulty, which require knowlege in the following areas:\ndynamic programming graph theory combinatorics The final level was indeed the most challenging and required me to understand permutation groups and apply the Pólya enumeration theorem.\nUpon completion, I received a message encrypted in Base64, which translated to:\n{‘success’ : ‘great’,\n‘colleague’ : ’esteemed’,\n’efforts’ : ‘incredible’,\n‘achievement’ : ‘unlocked’,\n‘rabbits’ : ‘safe’,\n‘foo’ : ‘win!’}\nI really enjoyed solving these problems – thanks Mathew for the invite link!\n","date":1653955200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653955200,"objectID":"c797e04eb8efbd46e184a11a7416cb06","permalink":"https://jmcoholich.github.io/post/google_foobar/","publishdate":"2022-05-31T00:00:00Z","relpermalink":"/post/google_foobar/","section":"post","summary":"The Google Foobar challenge is a programming challenge used by Google for recruiting. You must be invited to participate (article with more info). The challenge contains five levels of increasing difficulty, which require knowlege in the following areas:","tags":null,"title":"I Completed the Google Foobar Challenge","type":"post"},{"authors":["Jeremiah Coholich"],"categories":null,"content":" ","date":1635724800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1635724800,"objectID":"401cfa4b19789bc887d7ec9efa8aa8cf","permalink":"https://jmcoholich.github.io/publication/dl_proj/","publishdate":"2021-11-01T00:00:00Z","relpermalink":"/publication/dl_proj/","section":"publication","summary":"I benchmark Meta Strategy Optimization against Domain Randomization for sim2sim transfer. (CS 7643 Final Project)","tags":["unpublished"],"title":"Generalizing Learned Policies to Unseen Environments using Meta Strategy Optimization","type":"publication"},{"authors":["Jeremiah Coholich"],"categories":null,"content":" ","date":1619827200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1619827200,"objectID":"5aa2db01726ce59ae9c713bb170e87d8","permalink":"https://jmcoholich.github.io/publication/quals/","publishdate":"2021-05-01T00:00:00Z","relpermalink":"/publication/quals/","section":"publication","summary":"I review two sim2real transfer papers for robotics and then propose a new method using an \"information bottleneck\". (Robotics PhD Qualifying Exam)","tags":["unpublished"],"title":"Sim2Real Transfer for Quadrupedal Locomotion","type":"publication"},{"authors":["Xiaofeng Guo","Bryan Blaise","Jennifer Molnar","Jeremiah Coholich","Shantanu Padte","Ye Zhao","Frank L. Hammond III"],"categories":null,"content":" ","date":1589500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589500800,"objectID":"90a067233e3915a94c301aeb8078988e","permalink":"https://jmcoholich.github.io/publication/cassie_foot_sensor/","publishdate":"2020-05-15T00:00:00Z","relpermalink":"/publication/cassie_foot_sensor/","section":"publication","summary":"2020 3rd IEEE International Conference on Soft Robotics (RoboSoft)","tags":["published"],"title":"Soft Foot Sensor Design and Terrain Classification for Dynamic Legged Locomotion","type":"publication"},{"authors":["Jeremiah Coholich","Cesar Santoyo","Angel Yam","Pratik Kunapuli"],"categories":null,"content":" ","date":1588291200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1588291200,"objectID":"1ada22affc09a5f2040202f9dc7e82ce","permalink":"https://jmcoholich.github.io/publication/stat_ml_class_proj/","publishdate":"2020-05-01T00:00:00Z","relpermalink":"/publication/stat_ml_class_proj/","section":"publication","summary":"We evaluate the performance of reinforcement learning and other control algorithms on the Open AI Gym CartPole environment. (ECE 6254 final project)","tags":["unpublished"],"title":"Reinforcement Learning for Dynamical Systems","type":"publication"},{"authors":["Gray Cortright Thomas","Jeremiah M Coholich","Luis Sentis"],"categories":null,"content":" ","date":1562544e3,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1562544e3,"objectID":"40c87c63868ca4ad38859f10aa5cd0e1","permalink":"https://jmcoholich.github.io/publication/arm_exo/","publishdate":"2019-07-08T00:00:00Z","relpermalink":"/publication/arm_exo/","section":"publication","summary":"2019 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (AIM)","tags":["published"],"title":"Compliance Shaping for Control of Strength Amplification Exoskeletons with Elastic Cuffs","type":"publication"},{"authors":["David Bourell","Jeremiah Coholich","Antione Chalancon","Abhimanyu Bhat"],"categories":null,"content":" ","date":1491004800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1491004800,"objectID":"5f9a9fe9497bc66505b576b465021e95","permalink":"https://jmcoholich.github.io/publication/sls_project/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/sls_project/","section":"publication","summary":"CIRP Annals Manufacturing Technology Vol. 1, 66, 2017","tags":["published"],"title":"Evaluation of energy density measures and validation for powder bed fusion of polyamide","type":"publication"},{"authors":null,"categories":null,"content":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum. Sed ac faucibus dolor, scelerisque sollicitudin nisi. Cras purus urna, suscipit quis sapien eu, pulvinar tempor diam. Quisque risus orci, mollis id ante sit amet, gravida egestas nisl. Sed ac tempus magna. Proin in dui enim. Donec condimentum, sem id dapibus fringilla, tellus enim condimentum arcu, nec volutpat est felis vel metus. Vestibulum sit amet erat at nulla eleifend gravida.\nNullam vel molestie justo. Curabitur vitae efficitur leo. In hac habitasse platea dictumst. Sed pulvinar mauris dui, eget varius purus congue ac. Nulla euismod, lorem vel elementum dapibus, nunc justo porta mi, sed tempus est est vel tellus. Nam et enim eleifend, laoreet sem sit amet, elementum sem. Morbi ut leo congue, maximus velit ut, finibus arcu. In et libero cursus, rutrum risus non, molestie leo. Nullam congue quam et volutpat malesuada. Sed risus tortor, pulvinar et dictum nec, sodales non mi. Phasellus lacinia commodo laoreet. Nam mollis, erat in feugiat consectetur, purus eros egestas tellus, in auctor urna odio at nibh. Mauris imperdiet nisi ac magna convallis, at rhoncus ligula cursus.\nCras aliquam rhoncus ipsum, in hendrerit nunc mattis vitae. Duis vitae efficitur metus, ac tempus leo. Cras nec fringilla lacus. Quisque sit amet risus at ipsum pharetra commodo. Sed aliquam mauris at consequat eleifend. Praesent porta, augue sed viverra bibendum, neque ante euismod ante, in vehicula justo lorem ac eros. Suspendisse augue libero, venenatis eget tincidunt ut, malesuada at lorem. Donec vitae bibendum arcu. Aenean maximus nulla non pretium iaculis. Quisque imperdiet, nulla in pulvinar aliquet, velit quam ultrices quam, sit amet fringilla leo sem vel nunc. Mauris in lacinia lacus.\nSuspendisse a tincidunt lacus. Curabitur at urna sagittis, dictum ante sit amet, euismod magna. Sed rutrum massa id tortor commodo, vitae elementum turpis tempus. Lorem ipsum dolor sit amet, consectetur adipiscing elit. Aenean purus turpis, venenatis a ullamcorper nec, tincidunt et massa. Integer posuere quam rutrum arcu vehicula imperdiet. Mauris ullamcorper quam vitae purus congue, quis euismod magna eleifend. Vestibulum semper vel augue eget tincidunt. Fusce eget justo sodales, dapibus odio eu, ultrices lorem. Duis condimentum lorem id eros commodo, in facilisis mauris scelerisque. Morbi sed auctor leo. Nullam volutpat a lacus quis pharetra. Nulla congue rutrum magna a ornare.\nAliquam in turpis accumsan, malesuada nibh ut, hendrerit justo. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus. Quisque sed erat nec justo posuere suscipit. Donec ut efficitur arcu, in malesuada neque. Nunc dignissim nisl massa, id vulputate nunc pretium nec. Quisque eget urna in risus suscipit ultricies. Pellentesque odio odio, tincidunt in eleifend sed, posuere a diam. Nam gravida nisl convallis semper elementum. Morbi vitae felis faucibus, vulputate orci placerat, aliquet nisi. Aliquam erat volutpat. Maecenas sagittis pulvinar purus, sed porta quam laoreet at.\n","date":1461715200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1461715200,"objectID":"1551ce708e26625310deb3a4c3e3ffec","permalink":"https://jmcoholich.github.io/project/example2/","publishdate":"2016-04-27T00:00:00Z","relpermalink":"/project/example2/","section":"project","summary":"An example of using the in-built project page.","tags":["Deep Learning"],"title":"Example Project","type":"project"},{"authors":null,"categories":null,"content":"During my freshman year at UT, I built a 3D printer using tools in the makerspace. I followed this tutorial: https://www.instructables.com/Building-a-3D-Printer-Under-200/\n","date":1451606400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1451606400,"objectID":"5732d8f7f35053342bc98405c13cf453","permalink":"https://jmcoholich.github.io/project/printer/","publishdate":"2016-01-01T00:00:00Z","relpermalink":"/project/printer/","section":"project","summary":"I built my own 3D printer","tags":["None"],"title":"Building my own 3D printer","type":"project"}]